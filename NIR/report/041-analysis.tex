\chapter{Анализ предметной области}

\section{Что такое машинное обучение?}

\textbf{ Определение:} Машинное обучение (далее МО)--- это процесс обучения части программного обеспечения, называемой моделью, позволяющей делать прогнозы или генерировать контент на основе данных~\cite{google}.

\textbf{Определение:} Модель --- это математическое соотношение, полученное на основе данных, которые система машинного обучения использует для прогнозирования~\cite{google}.

\section{Типы систем машинного обучения}

Системы МО можно выделить в следующие категории, в зависимости от того, как они учатся делать прогнозы или генерировать контент~\cite{google1}:
\begin{enumerate}[label=\arabic*), leftmargin=1.6\parindent]
    \item обучение под присмотром;
    \item обучение без присмотра;
    \item обучение с подкреплением;
    \item генеративный искусственный интеллект.
\end{enumerate}

\subsection{Обучение под присмотром}

Модели обучения с учителем могут делать прогнозы после просмотра большого количества данных с правильными ответами, а затем обнаружения связей между элементами данных, которые дают правильные ответы.
Такое поведение модели можно сравнить с поведением студента, который готовится к экзаменам, изучая старые варианты экзаменов и ответы к ним.
Как только студент натренируется на достаточном количестве старых экзаменов, он будет хорошо подготовлен к сдаче нового экзамена.
Эти системы МО "контролируются" в том смысле, что человек предоставляет системе МО данные с известными правильными ответами, поэтому такие системы также называются контролируемыми.
Задача модели в контролируемой системе --- найти связи в данных, которые дают правильный ответ~\cite{google1}.

Наиболее распространенным вариантом использования контролируемого обучения для получения числового прогноза является регрессия.

\subsubsection{Базовые концепции контролируемого обучения}

Контролируемое МО основано на следующих основных концепциях:
\begin{itemize}
    \item данные;
    \item модель;
    \item обучение;
    \item оценка.
\end{itemize}

\subsubsubsection{\textbf{Данные}}

Данные являются движущей силой машинного обучения.
Они поступают в виде слов и чисел, хранящихся в таблицах.
Связанные данные хранятся в наборе данных, например:
\begin{itemize}
    \item цены на жилье;
    \item информация о погоде;
\end{itemize}

Наборы данных состоят из отдельных примеров, содержащих функции и метки.
Пример можно рассматривать как аналог одной в электронной таблице.
Функция --- это значения, которые контролируемая модель использует для прогнозирования меток.
Метка --- это "ответ" или значение, которое модель должна предсказывать~\cite{google1}.
В модели погоды, которая предсказывать осадки, например, такими характеристиками могут быть широта, долгота, температура, влажность, облачность, направление ветра и атмосферное давление.
Меткой в данном примере является количество осадков.

Примеры, которые содержат как функции, так и метки, называются помеченными примерами.
Примеры, которые содержат только функции, называются немаркированными.
После создания модели, метка прогнозируется на основе функций~\cite{google}.

\subsubsubsection{\textbf{Характеристики набора данных}}

Набор данных характеризуется своим размером и разнообразием.
Размер указывает количество примеров.
Разнообразие указывает на диапазон, охватываемый этими примерами.
Хорошие наборы данных большие и очень разнообразные.

Некоторые наборы данных велики и разнообразны.
Однако некоторые наборы данных велики, но имеют низкое разнообразие, а некоторые небольшие, но очень разнообразны.
Другими словами, большой набор данных не гарантирует достаточного разнообразия, а очень разнообразный набор данных не гарантирует достаточного количества примеров.

Например, набор данных может содержать данные за 100 лет, но только за июль.
Использование этого набора данных для прогнозирования количества осадков в январе приведет к плохим прогнозам.
И наоборот, набор данных может охватывать всего несколько лет, но содержать каждый месяц.
Этот набор данных может давать плохие прогнозы, поскольку он не содержит достаточного количества лет для учета изменчивости.

Набор данных также можно охарактеризовать количеством его признаков.
Например, некоторые наборы погодных данных могут содержать сотни объектов, начиная от спутниковых изображений и заканчивая значениями облачности.
Другие наборы данных могут содержать только три или четыре характеристики, такие как влажность, атмосферное давление и температура.
Наборы данных с большим количеством функций могут помочь модели обнаружить дополнительные закономерности и сделать более точные
прогнозы.
Однако наборы данных с большим количеством объектов не всегда создают модели, которые дают более точные прогнозы, поскольку некоторые объекты могут не иметь причинно--следственной связи с меткой~\cite{google1}.

\subsubsubsection{\textbf{Модель}}

В обучении с учителем модель представляет собой сложный набор чисел, которые определяют математическую связь между конкретными шаблонами входных объектов и конкретными значениями выходных меток.
Модель обнаруживает эти закономерности посредством обучения.

\subsubsubsection{\textbf{Обучение}}

Прежде чем контролируемая модель сможет делать прогнозы, ее необходимо обучить.
Чтобы обучить модель, ей дается набор данных с помеченными примерами.
Цель модели --- найти лучшее решение для прогнозирования меток на основе функций.
Модель находит лучшее решение, сравнивая его прогнозируемое значение с фактическим значением метки.
На основе разницы между прогнозируемыми и фактическими значениями, определяемыми как потери, модель постепенно обновляет свое решение.
Другими словами, модель изучает математическую взаимосвязь между признаками и меткой, чтобы можно было делать оптимальные прогнозы на основе невидимых данных.

Например, если модель предсказала 2921 миллиметра дождя, но фактическое значение составило 1905 миллиметров, то модель модифицирует свое решение так, чтобы ее прогноз был ближе к 1905 миллиметров.
После того как модель рассмотрела каждый пример в наборе данных (в некоторых случаях несколько раз), она приходит к решению, которое в среднем дает прогнозы, близкие к истинному значению, для каждого из примеров.

На рисунках~\ref{img:training-a-model-01} ---\ref{img:training-a-model-03} демонстрированы шаги обучения модели.
\begin{enumerate}
    \item Модель принимает один помеченный пример и дает прогноз.
    \includeimage
    {training-a-model-01}
    {f}
    {H}
    {0.6\textwidth}
    {Модель машинного обучения, делающая прогноз на основе помеченного примера}
    \item Модель сравнивает прогнозируемое значение с фактическим значением и обновляет свое решение.
    \includeimage
    {training-a-model-02}
    {f}
    {H}
    {0.4\textwidth}
    {Модель машинного обучения обновляет прогнозируемое значение}
    \item Модель повторяет этот процесс для каждого помеченного примера в наборе данных.
    \includeimage
    {training-a-model-03}
    {f}
    {H}
    {0.5\textwidth}
    {Модель машинного обучения обновляет свои прогнозы для каждого помеченного примера в наборе обучающих данных}
\end{enumerate}

Таким образом, модель постепенно узнает правильную связь между функциями и меткой.
Это постепенное понимание также является причиной того, почему большие и разнообразные наборы данных создают более точную модель --- она получила больше данных с более широким диапазоном значений и уточнила понимание взаимосвязи между функциями и меткой.

\subsubsubsection{\textbf{Оценка}}

Обученная модель оценивается, чтобы определить, насколько точно она умеет делать прогнозы.
Самый распространенный способ оценки модели --- это сравнение прогноз модели, полученными на основе анализа немаркированных примеров, с истинными значениями метки.

На рисунке~\ref{img:evaluating-a-model} представлен пример оценки модели машинного обучения.
\includeimage
    {evaluating-a-model}
    {f}
    {H}
    {0.4\textwidth}
    {Оценка модели МО путем сравнения ее прогнозов с фактическими значениями}


\section{Регрессия}

\textbf{ Определение:} Регрессия --- это математическое выражение, отражающее зависимость математического ожидания одной случайной величины от других случайных величин~\cite{kemer}.

Модель регрессии предсказывает числовое значение.
Например, модель погоды, которая прогнозирует количество дождя в миллиметрах, является регрессионной моделью.

В таблице~\ref{tab:tabl1} приведены примеры регрессионных моделей.

\begin{table}[ht]
    \centering
    \caption{Примеры регрессионных моделей}
    \begin{tabularx}{\textwidth}{|X|X|X|}
        \hline
        Сценарий & Входные данные & Выходные данные \newline(числовой прогноз) \\
        \hline
        Будущая цена дома & Площадь участка, почтовый индекс, количество спален и ванных комнат, размер участка, процентная ставка по ипотеке, ставка налога на недвижимость, затраты на строительство и количество домов, выставленных на продажу в этом районе & Цена дома \\
        \hline
        Будущее время поездки & Исторические условия дорожного движения, расстояние до пункта назначения и погодные условия & Время в минутах и секундах до прибытия в пункт назначения \\
        \hline
    \end{tabularx}
    \label{tab:tabl1}
\end{table}

\subsection{Линейная регрессия}

\textbf{ Определение:} Линейная регрессия --- это статистический метод, используемый для поиска взаимосвязи между переменными.
В контексте машинного обучения линейная регрессия находит
связь между функциями и меткой~\cite{google}.

%Предположим, требуется спрогнозировать топливную экономичность автомобиля (в километрах на литр) на основе его веса.
%Для этого приведён следующий набор данных (~\ref{tab:tabl2}):
%
%\begin{table}[ht]
%    \centering
%    \caption{Пример набора данных для прогнозирования топливной экономичности}
%    \begin{tabularx}{\textwidth}{|X|X|}
%        \hline
%        Вес (кг) & Топливная экономичность (км / л) \\
%        \hline
%        1587.6 & 7.65 \\
%        \hline
%        1673.8 & 6.38 \\
%        \hline
%        1560.4 & 7.65 \\
%        \hline
%        1555.8 & 6.80 \\
%        \hline
%        1968.6 & 6.38 \\
%        \hline
%        2005.9 & 5.95 \\
%        \hline
%        1075.0 & 10.20 \\
%        \hline
%    \end{tabularx}
%    \label{tab:tabl2}
%\end{table}
%
%На рисунке~\ref{img:car-data-points} представлен график зависимости топливной экономичности от веса автомобиля.
%
%\includeimage
%    {car-data-points}
%    {f}
%    {H}
%    {\textwidth}
%    {График зависимости топливной экономичности от веса автомобиля}
%
%На рисунке~\ref{img:car-data-points-with-model} представлена линия наилучшего соответствия через точки для создания собственной модели.
%
%\includeimage
%    {car-data-points-with-model}
%    {f}
%    {H}
%    {\textwidth}
%    {Линия наилучшего соответствия, проведенная на основе данных предыдущего рисунка}

Линейная регрессия является одним из наиболее популярных алгоритмов и чаще всего используется для начала решения любой задачи регрессии, так как считается простейшей моделью машинного обучения~\cite{kemer}.

В математической статистике линейная регрессия представляет собой метод аппроксимации зависимостей между входными и выходными переменными на основе линейной модели~\cite{loginom}.

Если рассматривается зависимость между одной входной и одной выходной переменными, то имеет место простая линейная регрессия.
Для этого определяется уравнение регрессии $y = ax + b$ и строится соответствующая прямая, известная как линия регрессии.

Коэффициенты $a$ и $b$, называемые также параметрами модели, определяются таким образом, чтобы сумма квадратов отклонений точек, соответствующих реальным наблюдениям данных, от линии регрессии была бы минимальной.
Коэффициенты обычно оцениваются методом наименьших квадратов~\cite{loginom}.

На рисунке~\ref{img:linear-regression} представлен пример построения линии регресии.
\includeimage
{linear-regression}
{f}
{H}
{\textwidth}
{Пример построения линии регрессии}

Если рассматривается зависимость между несколькими входными и одной выходной переменными, то имеет место множественная линейная регрессия.
Соответствующее уравнение имеет вид (\ref{eq:1}):
\begin{equation}
    Y = b_0 + b_1 x_1 + b_2 x_2 + \cdots+ b_n x_n,
    \label{eq:1}
\end{equation}
где $n$ --- число входных переменных.

В данном случае модель будет описываться не прямой, а гиперплоскостью.
Коэффициенты уравнения множественной линейной регрессии подбираются так, чтобы минимизировать сумму квадратов отклонения реальных точек от этой гиперплоскостью~\cite{loginom}.

Линейная регрессия имеет много практических применений.
Большинство из них попадают в одну из двух категорий:
\begin{enumerate}[label=\arabic*), leftmargin=1.6\parindent]
    \item если целью является прогнозирование, линейную регрессию можно использовать для подгонки модели к наблюдаемому набору данных;
    \item если цель заключается в том, чтобы объяснить изменчивость выходной переменной, можно применить линейный регрессионный анализ для количественной оценки силы взаимосвязи между выходной и входными переменными.
\end{enumerate}

\subsection{Логистическая регрессия}

\textbf{ Определение:} Логистическая регрессия --- это статистическая модель, используемая для предсказания вероятности возникновения некоторого события путем подгонки данных к логистической кривой~\cite{kras}.

Логистическая регрессия применяется для предсказания вероятности возникновения некоторого события по значениям множества признаков.
Для этого вводится так называемая зависимая переменная $y$, принимающая лишь одно из двух значений ---, как правило, это числа 0 (событие не произошло) и 1 (событие произошло), и множество
независимых переменных (также называемых признаками, предикторами или регрессорами) --- вещественных $x_1, x_2, \cdots, x_n$, на основе значений которых требуется вычислить вероятность принятия того или иного значения зависимой переменной~\cite{kras}.

Стандартная логистическая функция, также известная как сигмовидная функция (\textit{сигмовидная} означает «s-образная»), имеет формулу (\ref{eq:2}):
\begin{equation}
    f(x) = \frac{1}{1 + e^{-x}}.
    \label{eq:2}
\end{equation}

На рисунке~\ref{img:sigmoid_function_with_axes} показан соответствующий график сигмовидной функции.
По мере увеличения входного значения $x$ выходной сигнал сигмовидной функции приближается, но никогда не достигает 1.
Точно так же, когда входные данные уменьшаются, выходные данные сигмовидной функции приближаются, но никогда не достигают 0.
\includeimage
{sigmoid_function_with_axes}
{f}
{H}
{\textwidth}
{График сигмовидной функции}

Линейный компонент модели логистической регрессии описывается следующим уравнением (\ref{eq:3}):
\begin{equation}
    z = b + w_1 x_1 + w_2 x_2 +\cdots + w_n x_n,
    \label{eq:3}
\end{equation}
где $n$ --- число входных переменных, $z$ --- результат линейного уравнения (логарифм шансов), $b$ --- смещение.
Значения $w$ представляют собой изученные веса модели.
Значения $x$ --- это значения признаков для конкретного примера.

Чтобы получить прогноз логистической регрессии, значение $z$ затем передается сигмовидной функции, что дает значение (вероятность) от 0 до 1 (формула~\ref{eq:4}):
\begin{equation}
    y' = \frac{1}{1 + e^{-z}},
    \label{eq:4}
\end{equation}
где $y'$ --- результат модели логистической регрессии, $z$ --- линейный выход (рассчитанный в уравнении~\ref{eq:3}).

На рисунке~\ref{img:linear_to_logistic} показано, как линейный результат преобразуется в результат логистической регрессии.
\includeimage
{linear_to_logistic}
{f}
{H}
{\textwidth}
{Слева: график линейной функции z = 2x + 5, выделены три точки. Справа: сигмовидная кривая с теми же тремя точками, выделенными после преобразования сигмовидной функцией}

В качестве функции потерь в линейной регрессии используется метод наименьших квадратов (квадрат потерь).
Этот метод подходит для линейной модели, где скорость изменения выходных значений постоянна.
Например, для линейной модели $y' = b + 3 x_1$ каждый раз, когда увеличивается входное значение $x_1$ на 1, выходное значение $y'$ увеличивается на 3~\cite{google2}.

Однако скорость изменения модели логистической регрессии не является постоянной.
Когда значение логарифма шансов ($z$) ближе к 0, небольшое увеличение $z$ приводит к гораздо большим изменениям $y$, чем когда $z$ является большим положительным или отрицательным числом.

В таблице~\ref{tab:tabl2} показаны выходные данные сигмовидной функции для входных значений от 5 до 10, а также соответствующая точность, необходимая для учета различий в результатах.
\begin{table}[ht]
    \centering
    \caption{Выходные данные сигмовидной функции}
    \begin{tabularx}{\textwidth}{|X|X|X|}
        \hline
        6 & 0.997 & 3 \\
        \hline
        7 & 0.999 & 3 \\
        \hline
        8 & 0.9997 & 4 \\
        \hline
        9 & 0.9999 & 4 \\
        \hline
        10 & 0.99998 & 5 \\
        \hline
    \end{tabularx}
    \label{tab:tabl2}
\end{table}

Если бы использовался квадрат потерь для расчета ошибок для сигмоидальной функции, по мере того как выходные данные становятся все ближе и ближе к 0 и 1, потребовалось бы больше памяти, чтобы сохранить точность, необходимую для отслеживания этих значений~\cite{google2}.

Вместо этого функция потерь для логистической регрессии --- Log Loss.
Уравнение Log Loss возвращает логарифм величины изменения, а не
просто расстояние от данных до прогноза.
Потери журнала рассчитываются следующим образом (\ref{eq:5}):
\begin{equation}
    \text{Log Loss} = \sum_{(x, y)\in D} -y\log(y') - (1 - y)\log(1 - y'),
    \label{eq:5}
\end{equation}
где $(x,y)\in D$ --- это набор данных, содержащий множество помеченных примеров, которые $(x,y)$ пары, $y$ --- это метка в помеченном примере (0 или 1), $y'$ --- это прогноз модели (между 0 и 1), учитывая набор функций в $x$.

Для улучшения обобщающей способности получающейся модели, то есть уменьшения эффекта переобучения, на практике часто рассматривается логистическая регрессия с регуляризацией.





